# ê²€í†  ì˜ê²¬ ë° ê°œì„  ê³„íš

> **ê²€í† ì¼**: 2025-12-17
> **ê²€í† ì**: ì‚¬ìš©ì (í’ˆì§ˆ ê´€ë¦¬ ì „ë¬¸ê°€)
> **ëŒ€ìƒ ë¬¸ì„œ**: STD_BASED_QC_SYSTEM_PLAN.md
> **ìƒíƒœ**: ğŸŸ¡ ê°œì„  ì‘ì—… ì§„í–‰ ì¤‘

---

## ğŸ“‹ ê²€í†  ê²°ê³¼ ìš”ì•½

### ì¢…í•© í‰ê°€

| í•­ëª© | í‰ì  | ì½”ë©˜íŠ¸ |
|------|------|--------|
| **ê¸°ìˆ ì  íƒ€ë‹¹ì„±** | â˜…â˜…â˜…â˜…â˜† (4/5) | ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ì¬ì‚¬ìš©, ì•„í‚¤í…ì²˜ ëª…í™• |
| **ì¼ì • í˜„ì‹¤ì„±** | â˜…â˜…â˜…â˜†â˜† (3/5) | MVP ìš°ì„ ìˆœìœ„ íƒ€ë‹¹í•˜ë‚˜ 10ì£¼ëŠ” ë„ì „ì  |
| **ìš°ì„ ìˆœìœ„ ì ì ˆì„±** | â˜…â˜…â˜…â˜…â˜… (5/5) | P0/P1/P2 êµ¬ë¶„ ëª…í™•, ë‹¨ê³„ë³„ ê³„íš êµ¬ì²´ì  |
| **ì „ë°˜ì  í‰ê°€** | â˜…â˜…â˜…â˜…â˜† (4/5) | **íƒ„íƒ„í•œ ê¸°ì´ˆ, ì„±ëŠ¥ ê²€ì¦ ë° ìš´ì˜ ê°•í™” í•„ìš”** |

**í•œ ì¤„ ìš”ì•½**:
> "íƒ„íƒí•œ ê¸°ì´ˆ ìœ„ì— ì„¤ê³„ëœ STD ê¸°ë°˜ í’ˆì§ˆ ê²€ì‚¬ ì‹œìŠ¤í…œì´ì§€ë§Œ, ê³ ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜ ê²€ì¦ê³¼ ìš´ì˜ ì•ˆì „ì„± í™•ë³´ê°€ ê³¼ì œë¡œ ë‚¨ì•„ìˆìŒ."

---

## âœ… ê¸ì •ì  ì¸¡ë©´

### 1. ê¸°ìˆ  ê¸°ë°˜ì˜ ê²¬ê³ í•¨
- âœ… ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ì„± (94.7% í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€)
- âœ… ê·¹ì¢Œí‘œ ë³€í™˜, CIEDE2000, Zone ë¶„í•  ë“± í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ
- âœ… ê¸°ì¡´ ê¸°ëŠ¥ì„ ì¬í™œìš©í•˜ì—¬ STD í”„ë¡œíŒŒì¼ ìƒì„± ê°€ëŠ¥

### 2. ëª…í™•í•œ ì•„í‚¤í…ì²˜
- âœ… 3-tier êµ¬ì¡° (Frontend/Backend/DB) ëª…í™•
- âœ… ì„œë¹„ìŠ¤ë³„ ëª¨ë“ˆí™” (STD Profile/Comparison/Judgment)
- âœ… FastAPI ê¸°ë°˜ REST APIë¡œ ìœ ì—°í•œ í™•ì¥ ê°€ëŠ¥

### 3. êµ¬ì²´ì ì¸ ì›Œí¬í”Œë¡œìš°
- âœ… STD ë“±ë¡ â†’ ì–‘ì‚° ë¹„êµ â†’ ì¡°ì¹˜ ê¶Œì¥ â†’ íŒì • ì „ ë‹¨ê³„ ì •ì˜
- âœ… ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ 3ê°€ì§€ ëª…í™• (ì—”ì§€ë‹ˆì–´/ê²€ì‚¬ì/ê´€ë¦¬ì)

### 4. ì²´ê³„ì ì¸ ë‹¨ê³„ë³„ ê³„íš
- âœ… Phase 0~4 (10ì£¼) êµ¬ì²´ì  ë§ˆì¼ìŠ¤í†¤
- âœ… MVP (Week 6) ë²”ìœ„ ëª…í™•: STD ë“±ë¡ + ë¹„êµ ë¶„ì„ ê¸°ë³¸
- âœ… ìš°ì„ ìˆœìœ„ (P0/P1/P2) ì˜ êµ¬ë¶„ë¨

---

## âš ï¸ ìš°ë ¤ ì‚¬í•­

### 1. ì•Œê³ ë¦¬ì¦˜ ê³„ì‚° ë¹„ìš©
**ë¬¸ì œ**: DTW O(nÂ²) ë³µì¡ë„ë¡œ 3ì´ˆ ëª©í‘œ ë‹¬ì„± ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ

**ìƒì„¸**:
- Radial Profile ê¸¸ì´: ~500 í¬ì¸íŠ¸
- DTW ê³„ì‚°: 500 Ã— 500 = 250,000 ì—°ì‚°
- 3ê°œ ì±„ë„ (L, a, b) â†’ 750,000 ì—°ì‚°
- ì¶”ê°€ ì•Œê³ ë¦¬ì¦˜ (ìƒê´€ê³„ìˆ˜, KS test) í¬í•¨ ì‹œ ë” ì¦ê°€

**ì˜í–¥**:
- ë¹„êµ ë¶„ì„ > 3ì´ˆ â†’ ì‚¬ìš©ì ê²½í—˜ ì €í•˜
- ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ë³‘ëª© ë°œìƒ

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë¬¸ì œ
**ë¬¸ì œ**: JSON ì¹¼ëŸ¼ ê³¼ë‹¤ ì‚¬ìš© â†’ ê²€ìƒ‰/ë¶„ì„ ë¹„íš¨ìœ¨

**ìƒì„¸**:
```sql
-- í˜„ì¬ ì„¤ê³„
profile_data JSON  -- í”„ë¡œíŒŒì¼ ì „ì²´ë¥¼ JSONì—
color_data JSON    -- ìƒ‰ìƒ í†µê³„ ì „ì²´ë¥¼ JSONì—

-- ë¬¸ì œì 
SELECT * FROM std_profiles
WHERE color_data->>'zones'->0->'mean_lab'->0 > 70.0  -- ë³µì¡, ì¸ë±ìŠ¤ ë¶ˆê°€
```

**ì˜í–¥**:
- Zoneë³„ í‰ê· ê°’ ê²€ìƒ‰ ì–´ë ¤ì›€
- í†µê³„ ë¶„ì„ (í‰ê·  Î”E, íŠ¸ë Œë“œ) ë¹„íš¨ìœ¨
- PostgreSQL JSON í•¨ìˆ˜ ì˜ì¡´

### 3. ìš´ì˜ ìš”êµ¬ì‚¬í•­ ëˆ„ë½
**ë¬¸ì œ**: ë³´ì•ˆ, ë°±ì—…, ê°ì‚¬ ë¡œê·¸ ë¯¸ê³„íš

**ëˆ„ë½ í•­ëª©**:
- [ ] ì‚¬ìš©ì ì¸ì¦/ê¶Œí•œ ê´€ë¦¬
- [ ] STD ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš°
- [ ] ê°ì‚¬ ë¡œê·¸ (ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„)
- [ ] ë°±ì—… ë° ë³µêµ¬ ì „ëµ
- [ ] ì´ë¯¸ì§€ íŒŒì¼ ê´€ë¦¬ (DB vs íŒŒì¼ì‹œìŠ¤í…œ)

**ì˜í–¥**:
- ë°ì´í„° ë¬´ê²°ì„± ìœ„í˜‘
- ê·œì • ì¤€ìˆ˜ (Compliance) ë¬¸ì œ
- ì¥ì•  ë³µêµ¬ ì§€ì—°

### 4. ì¼ì • ë¦¬ìŠ¤í¬
**ë¬¸ì œ**: 10ì£¼ì— ëª¨ë“  ê¸°ëŠ¥ ì™„ì„±ì€ ë„ì „ì 

**ì„¸ë¶€ ë¦¬ìŠ¤í¬**:
- Phase 2 (ë¹„êµ ì—”ì§„ 3ì£¼): ì•Œê³ ë¦¬ì¦˜ ê°œë°œ + ê²€ì¦ + UI
- Phase 3 (ê¶Œì¥ 2ì£¼): ì‹¤ì¸¡ ë°ì´í„° ê¸°ë°˜ íŠœë‹ í•„ìš”
- ì˜ˆì™¸ ì²˜ë¦¬ (ë¶ˆì™„ì „ ì´ë¯¸ì§€, ë³µìˆ˜ ë Œì¦ˆ ë“±) ë¯¸ê³ ë ¤

**ì˜í–¥**:
- ì¼ì • ì§€ì—° ê°€ëŠ¥ì„± 50% ì´ìƒ
- í’ˆì§ˆ í¬ìƒ ë˜ëŠ” ë²”ìœ„ ì¶•ì†Œ í•„ìš”

---

## ğŸ”§ ê°œì„  ì œì•ˆ (ë°˜ì˜ ê³„íš)

### 1. ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ê°•í™” ğŸ”´ P0

#### 1.1 DTW ìµœì í™”
```python
# í˜„ì¬ ê³„íš
from dtaidistance import dtw
distance = dtw.distance(test, std)  # O(nÂ²)

# ê°œì„ ì•ˆ
from dtaidistance import dtw_ndim
# 1) FastDTW ì‚¬ìš© (ê·¼ì‚¬ ì•Œê³ ë¦¬ì¦˜, O(n))
distance = dtw_ndim.distance_fast(test, std, window=10)

# 2) í”„ë¡œíŒŒì¼ ë‹¤ìš´ìƒ˜í”Œë§
test_downsampled = test[::2]  # 500 â†’ 250 í¬ì¸íŠ¸
std_downsampled = std[::2]

# 3) C ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©
import dtw_c  # Custom C extension
```

#### 1.2 ëŒ€ì•ˆ ì•Œê³ ë¦¬ì¦˜ ì¶”ê°€
```python
# Cross-correlation (ìƒê´€ê³„ìˆ˜ë³´ë‹¤ ì´ë™ í—ˆìš©)
from scipy.signal import correlate
corr = correlate(test, std, mode='valid')
max_corr = np.max(corr) / (len(test) * np.std(test) * np.std(std))

# PCA ê¸°ë°˜ í˜•íƒœ ë¹„êµ
from sklearn.decomposition import PCA
pca = PCA(n_components=5)
test_pca = pca.fit_transform(test.reshape(-1, 1))
std_pca = pca.transform(std.reshape(-1, 1))
distance_pca = np.linalg.norm(test_pca - std_pca)
```

#### 1.3 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```python
# Phase 0ì— í¬í•¨í•  í”„ë¡œí† íƒ€ì…
def benchmark_algorithms():
    profiles = load_sample_profiles(n=100)

    algorithms = {
        "pearson": profile_correlation,
        "dtw_full": profile_dtw_distance,
        "dtw_fast": profile_dtw_fast,
        "cross_corr": profile_cross_correlation,
    }

    for name, func in algorithms.items():
        times = []
        for i in range(100):
            start = time.time()
            func(profiles[i], profiles[0])
            times.append(time.time() - start)

        print(f"{name}: avg={np.mean(times):.3f}s, max={np.max(times):.3f}s")

    # ëª©í‘œ: avg < 1.0s, max < 3.0s
```

**ì¼ì •**: Phase 0 (Week 1) - ë²¤ì¹˜ë§ˆí¬ ë° ì•Œê³ ë¦¬ì¦˜ ì„ ì •

---

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ìµœì í™” ğŸ”´ P0

#### 2.1 JSON ìµœì†Œí™” + ì£¼ìš” í•„ë“œ ë¶„ë¦¬

**ê°œì„ ëœ ìŠ¤í‚¤ë§ˆ**:
```sql
CREATE TABLE std_profiles (
    id SERIAL PRIMARY KEY,
    sku_code VARCHAR(50) NOT NULL,
    version INTEGER NOT NULL,
    image_path VARCHAR(500) NOT NULL,

    -- ğŸ”§ ì£¼ìš” í•„ë“œ ë¶„ë¦¬ (ê²€ìƒ‰/ì¸ë±ìŠ¤ ê°€ëŠ¥)
    zone_count INTEGER,
    overall_mean_L FLOAT,
    overall_mean_a FLOAT,
    overall_mean_b FLOAT,
    overall_delta_e_std FLOAT,  -- í‘œì¤€í¸ì°¨

    -- JSON (ìƒì„¸ ë°ì´í„°ë§Œ)
    profile_data JSONB,  -- Radial profile raw data
    meta_data JSONB,     -- ì´¬ì˜ ì¡°ê±´, ìŠ¹ì¸ ì •ë³´

    -- ë²”ìœ„ ì„¤ì •
    upper_limit JSONB,
    lower_limit JSONB,

    -- ê°ì‚¬ ì •ë³´
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    created_by VARCHAR(100),
    approved_by VARCHAR(100),
    approved_at TIMESTAMP,
    is_active BOOLEAN DEFAULT TRUE,

    UNIQUE(sku_code, version)
);

CREATE TABLE std_profile_zones (
    id SERIAL PRIMARY KEY,
    std_profile_id INTEGER REFERENCES std_profiles(id) ON DELETE CASCADE,
    zone_name VARCHAR(10) NOT NULL,

    -- ğŸ”§ Zoneë³„ ìƒ‰ìƒ ì •ë³´ (ì¸ë±ìŠ¤ ê°€ëŠ¥)
    mean_L FLOAT NOT NULL,
    mean_a FLOAT NOT NULL,
    mean_b FLOAT NOT NULL,
    std_L FLOAT,
    std_a FLOAT,
    std_b FLOAT,

    -- ê²½ê³„ ì •ë³´
    r_start FLOAT,
    r_end FLOAT,

    -- ìƒì„¸ í†µê³„ (JSON)
    percentiles JSONB,

    pixel_count INTEGER,
    ink_pixel_count INTEGER
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_std_sku ON std_profiles(sku_code, is_active);
CREATE INDEX idx_std_zone_lab ON std_profile_zones(mean_L, mean_a, mean_b);
```

**ì¥ì **:
- âœ… Zoneë³„ ìƒ‰ìƒ ê²€ìƒ‰: `SELECT * FROM std_profile_zones WHERE mean_L > 70`
- âœ… í†µê³„ ë¶„ì„: `SELECT AVG(mean_L) FROM std_profile_zones WHERE zone_name='A'`
- âœ… ì¸ë±ìŠ¤ í™œìš© ê°€ëŠ¥

#### 2.2 ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ ì „ëµ

**í˜„ì¬ ê³„íš**: DB blob vs íŒŒì¼ì‹œìŠ¤í…œ (ë¯¸ì •)

**ê°œì„ ì•ˆ**: **íŒŒì¼ì‹œìŠ¤í…œ (ì¶”ì²œ)**
```python
# ì €ì¥ ê²½ë¡œ êµ¬ì¡°
data/
  std_images/
    SKU001/
      v1_20251217_150030.jpg
      v2_20251220_093015.jpg
    SKU002/
      v1_20251218_114522.jpg
  test_samples/
    SKU001/
      2025-12-17/
        sample_001.jpg
        sample_002.jpg

# DBì—ëŠ” ê²½ë¡œë§Œ ì €ì¥
image_path = "data/std_images/SKU001/v1_20251217_150030.jpg"
```

**ì¥ì **:
- âœ… DB í¬ê¸° ê´€ë¦¬ ìš©ì´
- âœ… ë°±ì—… ë³„ë„ ê´€ë¦¬ (ì´ë¯¸ì§€ íŒŒì¼ vs DB)
- âœ… íŒŒì¼ ì ‘ê·¼ ì†ë„ ë¹ ë¦„ (CDN ì—°ë™ ê°€ëŠ¥)

**ë‹¨ì **:
- âš ï¸ íŒŒì¼-DB ë™ê¸°í™” í•„ìš”
- âš ï¸ íŒŒì¼ ì‚­ì œ ì‹œ ê³ ì•„ ë ˆì½”ë“œ ë°©ì§€ ë¡œì§ í•„ìš”

**ì¼ì •**: Phase 0 (Week 1) - ìŠ¤í‚¤ë§ˆ í™•ì • ë° ë§ˆì´ê·¸ë ˆì´ì…˜

---

### 3. ìš´ì˜ ìš”êµ¬ì‚¬í•­ ì¶”ê°€ ğŸŸ¡ P1

#### 3.1 ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬

```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(20) NOT NULL,  -- admin, engineer, inspector
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE audit_logs (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    action VARCHAR(50) NOT NULL,  -- std_register, std_approve, test_compare
    target_type VARCHAR(50),      -- std_profile, test_sample
    target_id INTEGER,
    details JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

**ê¶Œí•œ ë§¤íŠ¸ë¦­ìŠ¤**:
| ì—­í•  | STD ë“±ë¡ | STD ìŠ¹ì¸ | ì–‘ì‚° ê²€ì‚¬ | ê²°ê³¼ ì¡°íšŒ | ë²”ìœ„ ì„¤ì • |
|------|---------|---------|----------|----------|----------|
| **Admin** | âœ… | âœ… | âœ… | âœ… | âœ… |
| **Engineer** | âœ… | âŒ | âœ… | âœ… | âŒ |
| **Inspector** | âŒ | âŒ | âœ… | âœ… | âŒ |

#### 3.2 STD ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš°

```python
class STDApprovalWorkflow:
    def register_std(self, image_path: str, sku: str, user: User) -> STDProfile:
        """STD ë“±ë¡ (ìƒíƒœ: PENDING)"""
        profile = self.manager.create_std_profile(image_path, sku)
        profile.status = "PENDING"
        profile.created_by = user.username
        self.db.save(profile)

        # ê°ì‚¬ ë¡œê·¸
        self.audit_log(user, "std_register", profile.id)

        return profile

    def approve_std(self, profile_id: int, approver: User) -> bool:
        """STD ìŠ¹ì¸ (ê´€ë¦¬ìë§Œ ê°€ëŠ¥)"""
        if approver.role != "admin":
            raise PermissionError("Only admin can approve STD")

        profile = self.db.get_std_profile(profile_id)
        profile.status = "ACTIVE"
        profile.approved_by = approver.username
        profile.approved_at = datetime.now()

        # ê¸°ì¡´ active STDë¥¼ ë¹„í™œì„±í™”
        self.db.deactivate_other_versions(profile.sku_code)

        self.db.save(profile)
        self.audit_log(approver, "std_approve", profile_id)

        return True
```

#### 3.3 ë°±ì—… ë° ë³µêµ¬ ì „ëµ

**ìë™ ë°±ì—…**:
```bash
# ì¼ì¼ ë°±ì—… (cron)
0 2 * * * /scripts/backup_db.sh   # DB ë¤í”„
0 3 * * * /scripts/backup_images.sh  # ì´ë¯¸ì§€ rsync

# backup_db.sh
pg_dump lens_inspection > /backups/db_$(date +%Y%m%d).sql
# 7ì¼ì¹˜ ë³´ê´€, ì´í›„ ì‚­ì œ
find /backups -name "db_*.sql" -mtime +7 -delete
```

**ë³µêµ¬ ì ˆì°¨**:
```markdown
1. DB ë³µêµ¬
   psql lens_inspection < /backups/db_20251217.sql

2. ì´ë¯¸ì§€ ë³µêµ¬
   rsync -av /backups/images/ /data/std_images/

3. ê²€ì¦
   - STD í”„ë¡œíŒŒì¼ ê°œìˆ˜ í™•ì¸
   - ì´ë¯¸ì§€ íŒŒì¼ ë¬´ê²°ì„± ì²´í¬ (md5sum)
   - ìµœì‹  í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì¬ë¶„ì„
```

**ì¼ì •**: Phase 1 (Week 2-3) - ì¸ì¦/ê¶Œí•œ êµ¬í˜„, Phase 2 (Week 4) - ë°±ì—… ìë™í™”

---

### 4. AI/ML ë„ì… ê³ ë ¤ ğŸŸ¢ P2 (ì¥ê¸°)

#### 4.1 ì¡°ì¹˜ ê¶Œì¥ í•™ìŠµ

```python
class InkAdjustmentRecommender:
    def __init__(self):
        self.model = None  # ì¶”í›„ ML ëª¨ë¸
        self.history = []  # ì—”ì§€ë‹ˆì–´ í”¼ë“œë°±

    def recommend(self, test_lab: np.ndarray, std_lab: np.ndarray) -> dict:
        """ìƒ‰ìƒ ì¡°ì • ê¶Œì¥"""
        # ì´ˆê¸°: Rule-based
        dL, da, db = test_lab - std_lab

        # ë‚˜ì¤‘: ML-based (í”¼ë“œë°± í•™ìŠµ)
        if self.model:
            adjustment = self.model.predict([[dL, da, db]])
        else:
            adjustment = self._rule_based(dL, da, db)

        return {
            "dL": float(adjustment[0]),
            "da": float(adjustment[1]),
            "db": float(adjustment[2]),
            "confidence": 0.8  # ëª¨ë¸ ì‹ ë¢°ë„
        }

    def collect_feedback(self, recommendation: dict, actual: dict, effective: bool):
        """ì—”ì§€ë‹ˆì–´ í”¼ë“œë°± ìˆ˜ì§‘"""
        self.history.append({
            "recommended": recommendation,
            "actual": actual,
            "effective": effective,
            "timestamp": datetime.now()
        })

        # 100ê±´ ì´ìƒ ìˆ˜ì§‘ ì‹œ ëª¨ë¸ í•™ìŠµ
        if len(self.history) >= 100:
            self._train_model()
```

#### 4.2 ì´ìƒ ê°ì§€ (Anomaly Detection)

```python
from sklearn.ensemble import IsolationForest

class AnomalyDetector:
    def __init__(self):
        self.model = IsolationForest(contamination=0.05)
        self.fitted = False

    def fit_std_samples(self, std_samples: List[STDProfile]):
        """ì •ìƒ STD ìƒ˜í”Œë¡œ í•™ìŠµ"""
        features = []
        for std in std_samples:
            # íŠ¹ì§• ì¶”ì¶œ: í”„ë¡œíŒŒì¼ í˜•íƒœ, ìƒ‰ìƒ ë¶„í¬ ë“±
            feat = self.extract_features(std)
            features.append(feat)

        self.model.fit(features)
        self.fitted = True

    def detect_anomaly(self, test_sample: dict) -> bool:
        """ì–‘ì‚° ìƒ˜í”Œì´ ë¹„ì •ìƒì¸ì§€ ê°ì§€"""
        if not self.fitted:
            return False

        feat = self.extract_features(test_sample)
        prediction = self.model.predict([feat])

        return prediction[0] == -1  # -1 = anomaly
```

**ì¼ì •**: v2.0 (Phase 4 ì´í›„, Week 11+)

---

## ğŸš¨ ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆ

### 1. ì˜¤ì§„ ìœ„í—˜ ì™„í™”

**ë¬¸ì œ**: ìë™ íŒì •ì´ ìˆ˜ë™ ê²€ì‚¬ì™€ ë¶ˆì¼ì¹˜

**ì™„í™” ë°©ì•ˆ**:
```python
# Phase 2ì— í¬í•¨í•  ê²€ì¦ í”„ë¡œì„¸ìŠ¤
class ComparisonValidator:
    def validate_accuracy(self, n_samples: int = 100):
        """ìë™ ë¹„êµ vs ìˆ˜ë™ ê²€ì‚¬ ì •í™•ë„ ê²€ì¦"""
        results = []

        for i in range(n_samples):
            # 1. ìë™ ë¹„êµ
            auto_result = self.engine.compare(test[i], std)

            # 2. ìˆ˜ë™ ê²€ì‚¬ (ì—”ì§€ë‹ˆì–´)
            manual_result = input(f"Sample {i}: PASS or FAIL? ")

            # 3. ì¼ì¹˜ìœ¨ ê³„ì‚°
            match = (auto_result.pass_fail == manual_result)
            results.append(match)

        accuracy = np.mean(results)
        print(f"Accuracy: {accuracy:.2%}")

        if accuracy < 0.95:
            print("âš ï¸ Accuracy too low! Adjust thresholds.")
            self.tune_thresholds()

        return accuracy
```

**ê²€ì¦ ë‹¨ê³„**:
1. Week 6 (MVP): 100ê°œ ìƒ˜í”Œë¡œ ì •í™•ë„ ì¸¡ì • (ëª©í‘œ > 90%)
2. Week 8: 1000ê°œ ìƒ˜í”Œë¡œ ì¬ê²€ì¦ (ëª©í‘œ > 95%)
3. ìš´ì˜ ì´ˆê¸° 3ê°œì›”: ì´ì¤‘ ê²€ì¦ (ìë™ + ìˆ˜ë™ ë³‘í–‰)

---

### 2. ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥

**ë¬¸ì œ**: STD í”„ë¡œíŒŒì¼ ì†ìƒ ë˜ëŠ” ì˜¤ìš©

**ì™„í™” ë°©ì•ˆ**:
```python
class STDIntegrityChecker:
    def validate_profile(self, profile: STDProfile) -> bool:
        """STD í”„ë¡œíŒŒì¼ ë¬´ê²°ì„± ê²€ì¦"""
        checks = [
            self._check_profile_length(profile),
            self._check_color_range(profile),
            self._check_zone_boundaries(profile),
            self._check_image_exists(profile),
        ]

        return all(checks)

    def _check_profile_length(self, profile: STDProfile) -> bool:
        """í”„ë¡œíŒŒì¼ ê¸¸ì´ ê²€ì¦"""
        expected = 500  # Â±10%
        actual = len(profile.structure["radial_profile"]["L"])
        return 450 <= actual <= 550

    def _check_color_range(self, profile: STDProfile) -> bool:
        """ìƒ‰ìƒ ê°’ ë²”ìœ„ ê²€ì¦"""
        for zone in profile.color["zones"]:
            L, a, b = zone["mean_lab"]
            if not (0 <= L <= 100 and -128 <= a <= 127 and -128 <= b <= 127):
                return False
        return True
```

**ë²„ì „ ê´€ë¦¬**:
```python
def update_std(self, sku: str, new_profile: STDProfile):
    """STD ì—…ë°ì´íŠ¸ (ìƒˆ ë²„ì „ ìƒì„±)"""
    # ê¸°ì¡´ ë²„ì „ ì¡°íšŒ
    current = self.db.get_active_std(sku)

    # ìƒˆ ë²„ì „ ìƒì„±
    new_profile.version = current.version + 1
    new_profile.is_active = False  # ìŠ¹ì¸ ì „ê¹Œì§€ ë¹„í™œì„±

    # ì €ì¥
    self.db.save(new_profile)

    # ë¡¤ë°± ê°€ëŠ¥í•˜ë„ë¡ ê¸°ì¡´ ë²„ì „ ìœ ì§€
    # (is_active=Falseë¡œ ë³€ê²½ë§Œ)
```

---

### 3. ì¼ì • ë¦¬ìŠ¤í¬ ì™„í™”

**ë¬¸ì œ**: 10ì£¼ ì¼ì • ë‹¬ì„± ì–´ë ¤ì›€

**ì™„í™” ë°©ì•ˆ**:

#### 3.1 ì¼ì • ì¬ì¡°ì • (ë²„í¼ ì¶”ê°€)

| Phase | ì›ë˜ | ì¡°ì • í›„ | ë²„í¼ |
|-------|------|---------|------|
| Phase 0: ê¸°ë°˜ | 1ì£¼ | **1.5ì£¼** | +0.5ì£¼ (ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬) |
| Phase 1: STD í”„ë¡œíŒŒì¼ | 2ì£¼ | **2.5ì£¼** | +0.5ì£¼ (ì¸ì¦/ê¶Œí•œ) |
| Phase 2: ë¹„êµ ì—”ì§„ | 3ì£¼ | **4ì£¼** | +1ì£¼ (ì•Œê³ ë¦¬ì¦˜ ê²€ì¦) |
| Phase 3: ì¡°ì¹˜ ê¶Œì¥ | 2ì£¼ | **2ì£¼** | - |
| Phase 4: ë²”ìœ„ ê´€ë¦¬ | 2ì£¼ | **v2.0ìœ¼ë¡œ ì—°ê¸°** | - |
| **í•©ê³„** | 10ì£¼ | **10ì£¼ (MVP ë²”ìœ„ ì¶•ì†Œ)** | - |

**MVP ë²”ìœ„ ì¬ì •ì˜** (Week 10):
- âœ… STD ë“±ë¡ ë° ìŠ¹ì¸ (ì¸ì¦ í¬í•¨)
- âœ… ì–‘ì‚° ìƒ˜í”Œ ë¹„êµ (êµ¬ì¡° + ìƒ‰ìƒ ìœ ì‚¬ë„)
- âœ… ë¹„êµ ë¦¬í¬íŠ¸ UI
- âœ… ì¡°ì¹˜ ê¶Œì¥ (Rule-based)
- âŒ ë²”ìœ„ ê´€ë¦¬ (v2.0ìœ¼ë¡œ ì—°ê¸°)
- âŒ AI/ML ê¸°ëŠ¥ (v2.0ìœ¼ë¡œ ì—°ê¸°)

#### 3.2 ì£¼ê°„ ì²´í¬í¬ì¸íŠ¸

```
Week 1.5: âœ… DB ìŠ¤í‚¤ë§ˆ, ì•Œê³ ë¦¬ì¦˜ ë²¤ì¹˜ë§ˆí¬
Week 4: âœ… STD ë“±ë¡/ìŠ¹ì¸ ì™„ë£Œ, ì¸ì¦ êµ¬í˜„
Week 8: âœ… ë¹„êµ ì—”ì§„ ì™„ë£Œ, ì •í™•ë„ ê²€ì¦ (95% ì´ìƒ)
Week 10: âœ… MVP ë¦´ë¦¬ìŠ¤, ì¡°ì¹˜ ê¶Œì¥ í¬í•¨
```

---

### 4. ìš´ì˜ ì¤‘ë‹¨ ìœ„í—˜ ì™„í™”

**ë¬¸ì œ**: ì‹œìŠ¤í…œ ì¥ì•  ì‹œ ë³µêµ¬ ì§€ì—°

**ì™„í™” ë°©ì•ˆ**:

#### 4.1 í—¬ìŠ¤ ì²´í¬

```python
from fastapi import FastAPI
from fastapi.responses import JSONResponse

app = FastAPI()

@app.get("/health")
def health_check():
    """ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""
    checks = {
        "database": check_db_connection(),
        "storage": check_image_storage(),
        "std_profiles": check_std_availability(),
    }

    healthy = all(checks.values())
    status_code = 200 if healthy else 503

    return JSONResponse(content=checks, status_code=status_code)

def check_std_availability():
    """í™œì„± STDê°€ ìˆëŠ”ì§€ í™•ì¸"""
    skus = ["SKU001", "SKU002", "SKU003"]
    for sku in skus:
        std = db.get_active_std(sku)
        if not std:
            return False
    return True
```

#### 4.2 ì¥ì•  ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”

```markdown
# ì¥ì•  ë³µêµ¬ ì ˆì°¨ (Disaster Recovery)

## 1. DB ì¥ì• 
1. ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ê³µì§€
2. ìµœì‹  ë°±ì—… í™•ì¸: `ls -lh /backups/db_*.sql`
3. DB ë³µêµ¬: `psql lens_inspection < /backups/db_YYYYMMDD.sql`
4. ë¬´ê²°ì„± ê²€ì¦: `SELECT COUNT(*) FROM std_profiles WHERE is_active=true`
5. ì„œë¹„ìŠ¤ ì¬ì‹œì‘

## 2. ì´ë¯¸ì§€ íŒŒì¼ ì†ìƒ
1. ì˜í–¥ ë²”ìœ„ í™•ì¸: `md5sum -c /data/checksums.txt`
2. ë°±ì—…ì—ì„œ ë³µêµ¬: `rsync -av /backups/images/ /data/std_images/`
3. STD í”„ë¡œíŒŒì¼ ì¬ê²€ì¦

## 3. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¥ì• 
1. ë¡œê·¸ í™•ì¸: `tail -f /var/log/lens_inspection/error.log`
2. ì¬ì‹œì‘: `systemctl restart lens-inspection`
3. í—¬ìŠ¤ ì²´í¬: `curl http://localhost:8000/health`
```

---

## ğŸ“Š ê°œì„  ê³„íš ìš°ì„ ìˆœìœ„

### P0 (í•„ìˆ˜, Week 1-6 MVP)
- [x] ~~ê²€í†  ì˜ê²¬ ë¬¸ì„œí™”~~ (ì™„ë£Œ)
- [ ] ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (Week 1.5)
- [ ] DB ìŠ¤í‚¤ë§ˆ ê°œì„  (Week 1.5)
- [ ] STD ë“±ë¡ ë° ìŠ¹ì¸ (Week 2-4)
- [ ] ë¹„êµ ì—”ì§„ êµ¬í˜„ (Week 5-8)
- [ ] ì •í™•ë„ ê²€ì¦ (Week 8)
- [ ] ì¡°ì¹˜ ê¶Œì¥ Rule-based (Week 9-10)

### P1 (ì¤‘ìš”, Week 7-10)
- [ ] ì‚¬ìš©ì ì¸ì¦/ê¶Œí•œ (Week 2-4)
- [ ] ê°ì‚¬ ë¡œê·¸ (Week 4)
- [ ] ë°±ì—… ìë™í™” (Week 4)
- [ ] í—¬ìŠ¤ ì²´í¬ (Week 10)

### P2 (ì¶”í›„, v2.0)
- [ ] ë²”ìœ„ ê´€ë¦¬ ì‹œìŠ¤í…œ
- [ ] AI/ML ì¡°ì¹˜ ê¶Œì¥
- [ ] ì´ìƒ ê°ì§€
- [ ] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (ì¦‰ì‹œ ì°©ìˆ˜)

### Week 1 (í˜„ì¬)
1. âœ… ê²€í†  ì˜ê²¬ ë°˜ì˜ ë¬¸ì„œ ì‘ì„± â† **í˜„ì¬ ì—¬ê¸°**
2. â­ï¸ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
3. â­ï¸ DB ìŠ¤í‚¤ë§ˆ í™•ì • (JSON ìµœì†Œí™”)
4. â­ï¸ SQLAlchemy ëª¨ë¸ ì •ì˜

### Week 1.5 (ë‹¤ìŒ ì£¼)
1. ì•Œê³ ë¦¬ì¦˜ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (100ê°œ ìƒ˜í”Œ)
2. ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ ì • (DTW vs FastDTW vs Cross-corr)
3. DB ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
4. Phase 1 ì°©ìˆ˜ (STD ë“±ë¡ API)

---

## ğŸ“ ë³€ê²½ ì´ë ¥

| ë‚ ì§œ | ë³€ê²½ ë‚´ìš© |
|------|----------|
| 2025-12-17 | ì´ˆê¸° ì‘ì„± (ê²€í†  ì˜ê²¬ ë°˜ì˜) |
| 2025-12-17 | ì•Œê³ ë¦¬ì¦˜ ìµœì í™”, DB ê°œì„ , ìš´ì˜ ìš”êµ¬ì‚¬í•­ ì¶”ê°€ |
| 2025-12-17 | ë¦¬ìŠ¤í¬ ì™„í™” ë°©ì•ˆ, ì¼ì • ì¬ì¡°ì • |

---

**ì‘ì„±ì**: Claude Sonnet 4.5 (ì‚¬ìš©ì ê²€í†  ê¸°ë°˜)
**ë¬¸ì„œ ìœ„ì¹˜**: `docs/planning/REVIEW_FEEDBACK_AND_IMPROVEMENTS.md`
