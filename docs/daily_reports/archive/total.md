콘택트렌즈 색상 검사 시스템 통합 구현 계획서
1. 프로젝트 개요 및 목적

콘택트렌즈의 인쇄 및 색상 품질을 자동으로 검사하는 머신비전 시스템을 구축한다. 기존 수작업 육안 검사나 블랙박스 형태의 딥러닝 모델은 데이터 확보 비용이나 결과 해석의 어려움 등의 한계가 있다. 본 프로젝트에서는 콘택트렌즈의 동심원 패턴이라는 기하학적 특성을 활용한 규칙 기반(Rule-based) 색상 검사 기법을 적용하여, 적은 데이터로도 빠르게 구축 가능하고 **설명가능성(XAI)**이 높은 품질 검사 시스템을 목표로 한다. 구체적으로, 렌즈의 반지름 방향(radial) 색상 분포를 1차원 프로파일로 변환하고 영역별 색차(ΔE)를 정량화함으로써, 제품을 Edge, Middle, Inner 등의 영역으로 구분하여 각 영역의 색상 편차를 측정하고 OK/NG 여부를 자동 판정한다. 이 접근법은 추가 학습 없이도 SKU별 기준 프로파일만 등록하면 되어 다품종 대응이 용이하며, ΔE 기반 수치는 품질 기준을 명확히 제시할 수 있다는 장점이 있다.

2. 시스템 구성 및 아키텍처

시스템은 고해상도 카메라로 촬영된 렌즈 이미지를 입력받아 실시간으로 색상 품질을 판정하는 일련의 파이프라인으로 구성된다. 아래는 주요 구성요소와 흐름이다:

입력 장치: 5메가픽셀 이상 산업용 카메라 및 균일 조명장치. 렌즈의 이미지를 캡처하며, 이미지 상에서 렌즈 지름이 약 1000픽셀 이상 확보되도록 설정. 조명은 돔 라이트 또는 확산판을 사용한 링 조명으로 균일도와 색온도(5000~6000K)를 유지한다. 이 하드웨어 환경을 통해 안정적인 이미지 품질과 색상 일관성을 확보한다.

영상 획득 및 전처리: ImageLoader 모듈이 파일 또는 카메라 스트림으로부터 이미지를 불러오고, 그레이스케일 변환 및 노이즈 제거 등의 기본 전처리를 수행한다. 필요에 따라 렌즈 주위의 ROI(관심영역)만 크롭하고 화이트 밸런스 보정을 적용하여 조명 변화에 대한 강건성을 높인다.

렌즈 검출: LensDetector 모듈은 입력 이미지에서 렌즈 위치와 크기를 찾는다. Hough Circle 변환이나 외곽 컨투어 분석을 통해 렌즈의 외곽 원형과 중심좌표 (x₀, y₀), 반경 R을 정밀하게 검출한다. 검출된 중심과 반경은 이후 색상 프로파일 추출에 사용된다. 만약 렌즈 검출이 실패하면 ROI를 확장하여 재시도하고, 그래도 안 될 경우 예외 처리하여 해당 렌즈를 배출하는 등 흐름을 안전하게 유지한다.

색상 프로파일 추출: RadialProfiler 모듈이 렌즈 영역의 이미지를 극좌표계로 변환하여(radial unwrap) 동심원 형태의 색상 분포를 반지름 방향 1D 신호로 추출한다. OpenCV의 warpPolar 함수를 활용하여 렌즈 이미지를 극좌표로 펼친 이미지를 얻은 뒤, 각 반지름 값에 대해 360도 방향으로 평균 색상을 계산하여 반지름에 따른 RGB 값을 구한다. 이 1D RGB 프로파일을 LAB 색공간으로 변환하여 L(밝기), a(색상축1), b*(색상축2)** 곡선을 얻는다. 아래 코드 스니펫은 이러한 radial 프로파일 계산 과정을 간략히 나타낸다:

# 극좌표 변환으로 렌즈 이미지를 펼쳐서 polar_img 생성 (shape: [R, Θ, 3])
polar_img = cv2.warpPolar(image, (maxRadius, 360), center=(cx, cy), maxRadius=maxRadius, flags=cv2.WARP_FILL_OUTLIERS)
# 반지름 방향 색상 평균 계산 (Θ 방향 평균)
radial_profile_rgb = polar_img.mean(axis=0)  # shape: [R, 3]
# RGB 프로파일을 LAB 색공간으로 변환
radial_profile_lab = cv2.cvtColor(radial_profile_rgb.reshape(1, -1, 3).astype(np.uint8), cv2.COLOR_BGR2LAB)
L_profile = radial_profile_lab[0,:,0]  # 각 반지름에 대한 L* 값 배열


구역 분할(Zone Segmentation): 프로파일 상에서 색상이 급변하는 지점을 찾아 렌즈를 **여러 영역(zone)**으로 구분한다. ZoneSegmenter 모듈은 LAB 프로파일이나 ΔE 곡선의 1차/2차 미분을 분석하여 변곡점을 검출하고, 이를 경계로 Edge(A), Mix(A-B), Middle(B), Mix(B-C), Inner(C) 등의 영역을 자동으로 구분한다. 혼합 영역(Mix)은 두 색상 영역이 겹치는 부분으로, 이 구간의 폭 역시 추출하여 인쇄 번짐 정도를 평가한다. 프로파일 smoothing(예: Savitzky-Golay 필터)을 적용하여 노이즈 영향을 줄인 후 피크 검출을 수행한다.

색상 품질 평가: ColorEvaluator 모듈은 각 구역의 색상을 기준 SKU의 이상적 색상 프로파일과 비교하여 ΔE 값을 계산하고 허용 기준과 비교한다. 미리 정의된 SKU별 **목표 LAB 값 및 허용 오차(ΔE 임계값)**를 불러와서, 구역별 평균 색상과의 ΔE(색차)를 CIEDE2000 방식으로 산출한다. 각 영역의 ΔE가 허용 범위 이내이면 OK로 간주하며, 초과 시 해당 영역에 결함이 있다고 판단한다. 또한 혼합 영역의 ΔE 변화나 폭도 기준과 비교해 번짐/농담 불량 여부를 판단한다. 이를 통해 최종적으로 해당 렌즈 샘플의 종합 OK/NG 판정을 내린다.

결과 출력 및 시각화: 판정 결과는 **Visualizer(UI)**를 통해 실시간으로 표시된다. 검사된 이미지 위에 **검출된 영역 경계와 불량 지점(예: NG 영역에 색상 강조)**을 오버레이하고, 한편으로는 반지름 대비 색상 프로파일 곡선을 그래프로 보여준다. GUI 대시보드에는 OK/NG 여부, 각 영역별 ΔE 값, 혼합 영역 폭 등의 주요 수치 지표가 함께 표시된다. 이러한 시각화는 운영자가 결과를 한눈에 이해하고, 필요 시 제조장비(MES)와 연동하여 생산 공정에 피드백할 수 있도록 돕는다.

로그 및 리포트: Logger/Reporter 모듈은 검사 결과를 **CSV 또는 내장 DB(SQLite)**에 누적 저장하고, NG로 판정된 렌즈의 이미지는 별도 폴더에 자동 보관한다. 또한 일별 검사 통계나 LOT별 불량률 등을 집계하여 **리포트(PDF/CSV)**를 생성하며, MES 연동이 필요한 경우 API 훅을 통해 실시간 OK/NG 신호를 전송할 수 있다. 로그 데이터는 향후 품질 분석이나 시스템 성능 개선을 위해 활용된다.

설정 및 SKU 관리: 다양한 렌즈 디자인(SKU)에 대응하기 위해 SkuConfigManager 모듈에서 SKU별 기준 프로파일과 임계치를 관리한다. 신규 제품에 대해서는 양품 이미지를 몇 장 등록하면 해당 평균 프로파일과 ΔE 분포로부터 자동으로 임계치를 설정하여 SKU 설정 JSON으로 저장한다. 이 모듈은 설정의 버전관리와 백업을 지원하여, 변경 이력이 남고 필요 시 이전 버전으로 롤백할 수 있다. 설정 변경 시에는 관리자 승인 절차를 거쳐 오배적용을 방지한다.

위 구성요소들은 모두 Python 기반으로 구현되며, 하나의 응용 프로그램으로 통합된다. 아래 디렉토리 구조는 주요 모듈들을 보여준다:

C:\X\ColorMeter\  ← 프로젝트 루트
├── config\                   # 시스템 설정 및 SKU별 기준 데이터
│   ├── system_config.json    # 카메라, 조명 등 하드웨어 설정
│   └── sku_db\               # SKU별 기준 프로파일 JSON 모음
├── data\                     # 데이터 저장 디렉터리
│   ├── raw_images\           # 원본 테스트 이미지
│   ├── ng_images\            # 검출된 불량 이미지 아카이빙
│   └── logs\                 # 검사 이력 CSV 또는 DB 파일
├── src\                      # 소스 코드
│   ├── algorithms\           # 핵심 영상 처리 알고리즘 모듈들
│   │   ├── lens_detector.py      # 렌즈 중심 (cx, cy) 및 반경 R 검출
│   │   ├── radial_profiler.py    # 극좌표 변환, 1D 색상 프로파일 생성
│   │   ├── zone_segmenter.py     # 변곡점 탐지, Zone 분할 알고리즘
│   │   └── color_evaluator.py    # ΔE 계산 및 OK/NG 판정 로직
│   ├── ui\                   # GUI 및 시각화 관련 모듈
│   │   ├── main_window.py        # 메인 대시보드 창 구현
│   │   ├── plotting.py           # 프로파일 그래프 및 오버레이 그리기
│   │   └── settings_dialog.py    # 설정(UI) 다이얼로그
│   ├── utils\                # 유틸리티 (카메라, 파일 입출력 등)
│   │   ├── camera.py             # 카메라 SDK 제어 인터페이스
│   │   └── file_io.py            # 이미지/JSON 로드 및 저장 유틸
│   ├── main.py               # 프로그램 실행 엔트리포인트
│   └── __init__.py
├── tests\                    # 단위 테스트 코드
├── requirements.txt          # 요구 패키지 목록 (라이브러리 버전 명시)
└── README.md                 # 프로젝트 소개 및 사용법


위 구조에서 볼 수 있듯이 알고리즘, UI, 유틸, 설정 등이 모듈화되어 있으며, 각 구성요소가 명확한 책임을 갖고 설계되었다. 이는 모듈 간 인터페이스를 명료하게 정의하여 개발과 유지보수를 용이하게 해준다.

3. 모듈별 책임과 인터페이스

시스템의 핵심 모듈들과 그 역할 및 인터페이스를 정리하면 다음과 같다:

ImageLoader: 이미지 입력 및 전처리 담당 모듈이다. load_from_file(path) 또는 load_from_camera(cam) 메소드를 통해 파일/카메라로부터 이미지를 획득하고, preprocess(image)에서 그레이스케일 변환, 노이즈 제거(가우시안 블러+바이레터럴 필터) 및 ROI 검출/크롭, 화이트 밸런스 보정 등을 수행한다. 이 모듈의 출력은 후속 처리를 위한 정제된 이미지 객체이다.

LensDetector: 렌즈 위치 검출 모듈이다. detect(image) 메소드는 전처리된 이미지를 입력받아 **렌즈의 중심 좌표 (cx, cy)**와 반지름 R을 산출한다. 구현은 OpenCV의 허프 원 검출(cv2.HoughCircles)을 사용하거나, 이진화 후 컨투어 최댓값으로 원형을 검출하는 방식으로 이루어진다. 보정된 ROI내에서 동작하며, 결과는 렌즈의 기하정보 (중심, 반경)를 담은 데이터 클래스 혹은 튜플로 반환된다. 검출 신뢰도가 낮으면 예외/경고를 발생시켜 처리 흐름 상에서 후속 조치를 취할 수 있도록 한다.

RadialProfiler: 동심원 색상 프로파일 추출 모듈이다. extract_profile(image, center, R) 형태로 호출되며, 전달받은 전체 렌즈 이미지와 검출된 중심/반경을 기반으로 극좌표 전개를 수행한다. 내부적으로 OpenCV warpPolar로 극좌표 변환한 후, 각 반지름에 해당하는 원형 링의 RGB 평균값을 계산하여 반지름 방향의 1차원 색상 배열을 구한다. 이 배열을 numpy와 skimage.color 등을 이용해 *Lab 프로파일**로 변환하고 반환한다. 출력 데이터 구조에는 반지름 배열과 각 반지름별 LAB값이 포함된다.

ZoneSegmenter: 색상 변화 구간(Zone) 분할 모듈이다. segment(lab_profile)로 LAB 프로파일 또는 ΔE(r) 곡선을 입력받아, **색 변화가 급격한 지점(변곡점)**들을 검출한다. numpy로 1차 미분, 2차 미분 배열을 계산하거나 scipy.signal.find_peaks 등을 활용하여 극값을 찾아내고, Edge, Middle, Inner 등의 영역 경계 r 값을 결정한다. 또한 Edge~Middle 사이, Middle~Inner 사이의 혼합(Mix) 구간 폭도 산출하여 리턴한다. 이 모듈의 출력은 zone 경계들이며, 후속 평가 모듈에서 해당 구간별 색상을 참고할 수 있도록 한다.

ColorEvaluator: 색차 계산 및 합격/불합격 판정 모듈이다. evaluate(lab_profile, zones, sku_config) 형태로 호출되며, 각 zone별 실제 색상(LAB)과 SKU 기준 색상을 비교하여 ΔE 값을 계산한다. ΔE 계산에는 국제표준 CIEDE2000 공식을 사용하며, colormath 또는 skimage.color.deltaE_ciede2000 함수를 활용한다. 예를 들어, 아래와 같이 ΔE를 계산할 수 있다:

from skimage import color
delta_E = color.deltaE_ciede2000(ref_lab, sample_lab)


SKU별 임계치 구성(sku_config)에는 각 zone에 대한 허용 최대 ΔE와 혼합 구간의 최대 폭 등이 저장되어 있으며, ColorEvaluator는 이를 참고하여 각 영역이 기준 내인지 여부를 판단한다. 모든 zone이 기준을 만족하면 OK, 하나라도 벗어나면 NG 판정을 내리며, 결과로 OK/NG 플래그와 영역별 ΔE 값 딕셔너리를 반환한다.

SkuConfigManager: SKU 설정 관리 모듈이다. 다양한 제품(SKU)마다 서로 다른 색상 디자인과 허용 오차가 있으므로, 이를 별도로 관리한다. SkuConfigManager는 SKU별 기준 프로파일 데이터, zone 경계, ΔE 임계값 등을 생성·저장·불러오는 기능을 제공한다. 신규 SKU 추가 시 여러 장의 양품 이미지로부터 자동으로 기준값을 생성하거나 수동 입력할 수 있으며, 내부적으로 ΔE 분포의 평균과 2σ 범위를 계산해 초기 임계치를 추천한다. 설정은 JSON/YAML로 버전관리되고, update, rollback 메소드를 통해 이력 관리와 복구가 가능하다. 또한 필요하면 UI의 설정 다이얼로그(settings_dialog.py)에서 사용자 친화적으로 SKU 설정을 편집할 수 있다.

Visualizer (UI): 결과 시각화 및 대시보드 모듈이다. PyQt6 기반의 GUI로 구현되며, main_window.py에서 메인 이벤트 루프와 창을 구성한다. 이 모듈은 Live View 패널(실시간 카메라 영상 또는 불러온 이미지), Overlay 패널(영상 위에 zone 경계와 NG 표시), Graph 패널($r$-프로파일 LAB 곡선 그래프), Status 패널(현재 SKU, 각 zone ΔE 값, 최종 OK/NG)을 포함한다. 내부적으로 Matplotlib 또는 PyQtGraph를 활용하여 그래프를 그리고, OpenCV를 통해 생성한 오버레이 이미지를 표시한다. 또한 사용자 입력(예: SKU 선택, 설정 변경, 이미지 캡처 트리거 등)을 받아 백엔드 모듈에 전달하는 컨트롤러 역할도 수행한다. Visualizer는 ColorEvaluator의 결과를 실시간으로 반영하여 운영자가 즉각적으로 품질 상태를 파악할 수 있게 한다.

Logger/Reporter: 로그 저장 및 리포팅 담당 모듈이다. logger 컴포넌트는 검사 실행 중 발생하는 이벤트와 결과를 파일로 기록하며 (예: Python logging 라이브러리 활용), 검사 결과는 logs/ 디렉토리에 CSV 형태로 축적된다. 또한, ng_images/ 디렉토리에 NG로 판정된 이미지가 자동 저장되어 결함 사례 아카이브를 구축한다. Reporter 기능은 누적된 데이터를 요약하여 일별/주별 통계 리포트를 생성하거나 대시보드에 추세 차트를 표시한다. 예를 들어, SKU별로 지난 1개월 간 zone별 평균 ΔE 추이를 시각화하거나, Lot별 NG률을 계산하여 출력할 수 있다. 이 모듈은 월간 품질 회고에 활용될 수 있는 데이터 기반 인사이트를 제공하며, 필요시 MES 등의 상위 시스템에 결과를 전송하는 인터페이스도 포함한다.

4. 기술 스택 및 사용 라이브러리

본 시스템은 Python 3.10+ 언어를 기반으로 개발된다. Python은 방대한 컴퓨터 비전/머신러닝 라이브러리 생태계와 빠른 프로토타이핑에 유리하여 선택되었다. 주요 기술 스택과 라이브러리 (및 버전)은 다음과 같다:

OpenCV 4.8.1 – 영상 획득 및 처리의 핵심 라이브러리이다. 렌즈 검출 (허프 변환, 컨투어 등), 극좌표 변환(warpPolar), 색공간 변환 등 대부분의 비전 기능을 활용한다.

NumPy 1.26 및 SciPy 1.11 – 수치 연산과 신호 처리에 사용된다. 이미지 데이터의 배열 연산, 미분 계산, Savitzky-Golay 필터 등의 구현에 활용한다.

scikit-image 0.22 또는 colormath 3.0 – 색상 과학 관련 연산에 사용된다. LAB 색공간 변환, ΔE (CIEDE2000) 계산을 정확하게 수행하기 위해 활용한다. (skimage.color.deltaE_ciede2000 함수 등)

Matplotlib 3.8 및 PyQtGraph 0.13 – 시각화 도구이다. 색상 프로파일 그래프를 그리거나, PyQt용 실시간 플롯을 위해 사용한다. Matplotlib은 정적 리포트 그래프에, PyQtGraph는 GUI 내 실시간 업데이트에 각각 장점을 지닌다.

PyQt6 6.6 – GUI 프레임워크로, 크로스플랫폼 데스크톱 애플리케이션을 만든다. 본 프로젝트에서는 PyQt로 실시간 대시보드를 구축하며, OpenCV 이미지를 PyQt로 표시하고 사용자 입력을 처리한다. (초기 프로토타입 단계에서는 간단히 Streamlit 1.29 등의 웹 대시보드로 구현해 볼 수도 있으나, 최종 시스템은 공장 PC 환경에서 독립 실행형으로 동작하도록 PyQt를 채택한다.)

Pandas 2.1 – 데이터 관리에 사용된다. 검사 결과 로그를 CSV로 저장/불러오거나 통계치를 계산할 때 활용할 수 있다. 다만 초기에는 복잡한 DB까지는 불필요하여 경량 저장으로 CSV/SQLite를 사용하고, 향후 확장 시 ORM으로 SQLAlchemy를 도입하거나 PostgreSQL 등으로 이관을 고려한다.

기타 유틸리티: pytest 7.4 (테스트 프레임워크), loguru 0.7 (향상된 로깅) 등을 사용하여 개발 생산성과 코드 품질을 유지한다. 또한 Basler Pylon SDK나 표준 GenICam 인터페이스 (예: pypylon, harvesters)를 통해 산업용 카메라 연동을 구현한다.

이상의 스택을 **requirements.txt**에 명시하여 공유하며, conda 또는 venv를 통해 일관된 개발 환경을 구성한다. 버전 관리는 Git으로 수행하고, 코드 포맷터(Black), 린터(Flake8), 타입 체커(mypy) 등을 활용해 코드 품질을 관리한다.

5. 단계별 개발 일정 (마일스톤 및 PoC)

프로젝트 개발은 약 4~5개월을 예상하며, 단계별로 명확한 목표 산출물을 설정한다. 각 단계의 기간과 주요 내용은 아래와 같다:

0단계: 준비 단계 (1주)

팀 세팅 및 환경 구축: 저장소(repo) 초기화 및 CI 파이프라인 설정, 코드 스타일 가이드 공유. Python 가상환경을 만들고 OpenCV, NumPy 등 필수 라이브러리 설치 확인.

요구사항 재확인: 제품별 색상 사양서 및 결함 기준 정리. 프로젝트 이해관계자(품질팀 등)로부터 기대 품질 지표(예: 허용 ΔE, 검사 속도)를 확정한다.

데이터 수집 계획: 기존 양품 및 불량 사례 이미지 수집 일정 수립. SKU별 최소 30장 이상의 양품 이미지와, 예상 불량 유형별 (번짐, 색 빠짐, 패턴 밀림 등) 20장 이상의 사례 데이터를 확보할 계획을 세운다. 데이터 부족 시에는 의도적으로 결함을 유발한 샘플을 제작하거나 합성 데이터를 활용하는 방안을 마련한다.

하드웨어 셋업 점검: 카메라 해상도, 렌즈, 조명 등 장비 사양 최종 확정 및 테스트. 조명 균일도와 화이트밸런스 기준을 정하고, 색상 캘리브레이션용 컬러차트 준비 (주기적 교정에 사용).

1단계: 핵심 알고리즘 프로토타입 개발 (3주)

렌즈 검출 & 프로파일 생성 구현: OpenCV로 원형 렌즈 검출 알고리즘을 구현하고 테스트. 이어 검출된 영역에 대해 radial 프로파일 추출 함수를 작성하여, 단일 이미지 입력 시 Lab* vs 반지름 그래프를 얻는다. 이때 결과를 손쉽게 시각화하기 위해 Jupyter 노트북이나 간단한 CLI 툴 형태로 개발하여 그래프와 오버레이 이미지를 출력해본다.

기본 색차 계산: 추출된 프로파일 상에서 Edge/Middle/Inner 등 주요 부분을 수동으로 구분하고, 해당 구간의 평균 색상 간 ΔE를 계산하는 실험 코드를 작성한다 (예: 중심부 vs 가장자리 색상차). 이를 통해 ΔE 계산 로직의 정확성을 검증하고, 특정 샘플에서 육안으로 인지된 색상 차이가 수치로 얼마나 나타나는지 확인한다.

프로토타입 검증: 다양한 SKU의 이미지를 수동으로 테스트하여 알고리즘이 정상 동작하는지 확인한다. 이 단계의 완료 기준은 **단일 이미지에 대해 주요 기능 (렌즈 검출, 프로파일 생성, ΔE 계산)**이 파이프라인으로 동작하고 결과를 시각적으로 검토할 수 있는 것이다. 또한 대략적인 처리 속도를 측정하여 1장당 수십 ms~수백 ms 수준임을 확인하고, 렌즈 미검출율이나 프로파일의 노이즈 수준을 파악한다.

2단계: 다품종 SKU 지원 및 자동 설정화 (4주)

SKU 기준 데이터 생성: 1단계 결과를 토대로, SKU별 양품 이미지들을 입력하면 자동으로 기준 프로파일과 임계치를 산출하는 스크립트를 개발한다. 예를 들어, 특정 SKU의 양품 30장을 로드하여 각자의 radial LAB 프로파일을 얻은 뒤, 각 반경 포인트의 평균 및 표준편차 프로파일을 계산한다. 그런 다음 zone 별로 분할하여 평균 ΔE와 2σ 범위를 구하고 이를 해당 SKU의 허용 한계로 설정한다. 이러한 내용을 JSON 형식의 SKU 설정 파일로 저장하는 기능을 구현한다.

SKU 관리 UI/CLI: 간단한 CLI 도구나 GUI 화면을 만들어, 사용자가 신규 SKU를 등록하고 기준 프로파일을 생성하도록 한다. 또한 SKU별 임계치(허용 ΔE)를 수동 조정하거나 버전간 비교할 수 있는 기능도 포함한다. 이때 설정 변경 시 검증(예: ΔE 한도를 지나치게 좁게 설정하지 않았는지 경고)과 백업/복원 기능을 구현하여 운영 안정성을 높인다.

자동 영역분할 알고리즘 개선: 1단계에서는 수동으로 zone을 구분했다면, 이 단계에서는 ZoneSegmenter의 자동 분할 알고리즘을 완성한다. Savitzky-Golay 필터로 프로파일을 평활화하고, 미분 기반으로 변곡점을 검출하여 zone을 나누는 로직을 튜닝한다. 여러 SKU의 양품 데이터에 이 알고리즘을 적용해보고, 과분할이나 미분 검출 실패 사례가 없는지 점검하여 영역 분할의 재현성을 확보한다.

단계 산출물: 이 단계가 끝나면 다품종 지원을 위한 설정 관리 시스템이 구축되어야 한다. 새로운 SKU 추가 시 수 시간 내에 기준치를 생성해 적용 가능하고, 기존 SKU의 설정 변경도 UI를 통해 안전하게 수행할 수 있어야 한다. 또한 여러 이미지 일괄 처리 테스트를 통해 자동 분할과 판정이 연속된 이미지 스트림에서도 문제없이 작동함을 확인한다. ΔE 값 분포를 분석하여 각 SKU별 초기 임계치가 적절한지 검증하고, 필요하면 품질팀과 상의하여 조정한다.

3단계: 품질 판정 고도화 및 성능 개선 (4주)

판정 로직 튜닝: 2단계까지 구축된 ΔE 기반 판정 로직을 현실적인 생산 편차에 맞게 튜닝한다. 각 SKU별로 양품 데이터를 통한 ΔE 분포를 분석해 false reject이 없도록 허용치를 조정하며, 반대로 불량 샘플들에 대해서는 ΔE가 임계치를 넘도록 민감도를 높인다. 특히 혼합(Mix) 영역의 색상 경계가 번지는 경우를 잡아내기 위해, ΔE 곡선의 기울기나 혼합 폭 등에 추가 기준을 설정한다.

조명/영상 변화 대응: 조명 세기 변화나 카메라 설정 편차에 강건하도록 전처리 강화를 한다. White balance(그레이월드假 등) 보정 함수의 효과를 평가하고, 히스토그램 평활화나 정규화 기법을 적용하여 환경 변화에 따른 ΔE 변화 영향을 최소화한다. 렌즈 위치 변화에 대비해 검출된 중심을 기준으로 일정 영역을 확실히 캡처하도록 ROI 마진을 재조정하고, 필요한 경우 이미지 회전 보정을 추가 검토한다.

성능 최적화: 전체 파이프라인의 처리 속도 프로파일링을 실시하고 병목을 최적화한다. 예를 들어, Python 루프 대신 NumPy 벡터화로 연산을 가속하고, 병렬로 처리할 수 있는 부분(예: 카메라 획득과 처리 병렬화)을 고려한다. 목표는 1장 처리에 200ms 이하로, 1분당 300장 이상 검사도 가능하도록 하는 것이다. 만일 고해상도 이미지 처리로 CPU 부하가 큰 경우, C++로 핵심 알고리즘을 재구현하거나 GPU를 활용하는 방안도 검토한다.

데이터 확대 및 검증: 이 단계에서 다양한 불량 데이터 확보가 이루어진다. 실제 생산라인에서 수집하거나 사전에 준비한 불량 렌즈들을 대량으로 시험하여, 시스템이 얼마나 검출하는지 측정한다. 특히 미세한 색 농도 차이, 패턴 찌그러짐 등의 현재 알고리즘으로 놓칠 수 있는 결함 사례를 점검한다. 필요한 경우 임계치를 더 조정하거나, 사람이 놓친 케이스에 대해서는 예외 규칙(예: 특정 영역 패턴 밀림 탐지)을 추가한다. 성능 평가 지표로 **민감도(결함 검출율)**와 특이도(정상 검증율), 오탐지율(FPR)/미탐지율(FNR)을 산출하며, 반복 측정 시 판정의 **일관성(재현성)**도 확인한다. 목표는 주요 불량 유형에 대해 95% 이상의 검출률을 달성하고, 정상 제품에 대해 5% 미만의 false NG가 나오도록 하는 것이다.

4단계: 시스템 통합 및 UI 구현 (4주)

실시간 처리 및 UI 통합: 3단계까지 개발된 백엔드 알고리즘을 PyQt6 기반 GUI 어플리케이션에 통합한다. 카메라에서 프레임을 받아 지정 폴더에 저장하고 처리하는 모드와, 라이브 스트리밍으로 바로 처리하는 모드를 구현한다. 처리 결과를 메인 대시보드 창의 각 패널(영상, 그래프, 상태)에 연동하고, 사용자 조작(예: 검사 시작/중지, SKU 변경 등)에 대한 핸들러를 작성한다.

하드웨어 I/O 연동: 산업현장 적용을 위해 카메라 트리거 신호, 컨베이어 인터페이스, 외부 신호등/알람장치와의 연동을 개발한다. 예를 들어, 디지털 I/O 제어 라이브러리를 사용해 NG 발생 시 라인에 신호를 주거나, PLC와 통신하여 컨베이어를 멈추는 등의 기능이다. 또한 MES 시스템 API와의 연결을 구축하여, 검사 결과 데이터를 실시간으로 상위 시스템에 전송하거나 혹은 주기적으로 결과 파일을 dropzone에 배치하는 방법 등을 구현한다.

배포 및 설치 준비: 현장 PC(산업용 컴퓨터, IPC)에 배포하기 위한 패키징을 진행한다. PyInstaller 등을 사용해 스탠드얼론 실행파일을 생성하거나, 가상환경 셋업 스크립트를 작성한다. 또한 시운전 매뉴얼과 설치/운영 매뉴얼을 작성하여, 현장 엔지니어가 시스템을 설치하고 조정할 수 있도록 한다. UI 사용법, SKU 추가 방법, 장애 발생시 조치 방안 등이 매뉴얼에 포함된다.

최종 검증: 통합된 시스템에 대해 입력부터 출력까지 시나리오 테스트를 실시한다. 예를 들어, 정상 제품 100개 연속 투입 시 모든 OK 확인, 불량 샘플 20개 투입 시 정확히 NG로 검출되는지 등을 시험한다. UI의 반응 속도(버튼 클릭 후 응답), 스루풋(렌즈 분당 처리량) 등을 측정하여 요구 수준을 만족하는지 확인한다. 필요한 경우 경미한 버그 수정과 최종 튜닝을 거쳐 현장 투입 준비를 완료한다.

5단계: 현장 PoC 테스트 (4주)

현장 설치 및 캘리브레이션: 실제 생산 라인에 시스템을 설치하고, 초기 캘리브레이션 절차를 수행한다. 조명 균일도와 카메라 초점을 점검하고, 준비된 컬러차트로 화이트밸런스를 조정하여 기준 상태로 맞춘다. 이 캘리브레이션은 PoC 기간 동안 정기적으로 (예: 주 1회) 실시하여 시스템이 항상 최적 상태를 유지하도록 한다.

시운전 및 데이터 수집: 일정 기간(4주 간) 동안 실제 제품 검사 공정에 시스템을 투입하여 **시운전(PoC)**을 진행한다. 하루에 수백 개 이상의 렌즈를 검사하며, 그 결과를 기존 육안 검사 결과와 비교 평가한다. 예를 들어 하루 200개 Lot에 대해, ΔE 측정값의 분포와 시간에 따른 변동을 분석하고, 기존에 놓쳤던 미세 불량을 잡아내는지 확인한다.

오탐/미검 검토 및 피드백: PoC 과정에서 발생한 **오탐지(정상인데 NG 판정)**나 미검지(불량을 OK로 놓침) 사례를 모두 기록하고 원인을 분석한다. 오탐의 경우 임계치가 너무 엄격한지, 조명 흔들림 등 외부 요인이 있었는지 등을 검토하고, 필요하면 해당 SKU의 설정을 조정하거나 알고리즘에 예외 처리를 추가한다. 미검의 경우 해당 유형의 결함이 알고리즘으로는 검출 어려운 유형인지 분석한다. 예컨대 패턴의 기하학적 어긋남(회전 불량)은 색상 ΔE만으로 어렵다면, 별도의 형상 검사 모듈 추가를 고려한다. 이러한 과정을 통해 시스템의 현장 적용 신뢰성을 최종 검증/개선한다.

PoC 결과 보고: PoC 종료 시, 그 동안의 검사 데이터와 개선 내용을 종합하여 결과 보고서를 작성한다. 이 보고서에는 주요 성능 지표(검출률, 오탐률, 처리 속도), 대표적인 NG 검출 사례 이미지, 현장 피드백, 향후 개선 사항 등이 포함된다. 경영진/품질팀에 PoC 결과를 공유하여 정식 양산 적용 승인을 얻는 것이 목표이다.

6단계: 고급 기능 R&D 및 향후 계획 (선택적, 병행)

머신러닝 이상 탐지 병행 연구: 운영 안정화 후, 더 어려운 결함 탐지를 위해 비지도 학습 기반 이상 탐지 기법(PatchCore, PaDiM 등) 적용을 연구한다. 소량의 정상/불량 데이터셋으로 PatchCore를 학습시키고, PoC 기간 중 현재 룰 기반 방식과 **검출 성능(AUROC 등)**을 비교 평가한다. PatchCore의 경우 95% 이상의 검출 정확도를 기대할 수 있으나, 구현 복잡도 및 추론 시간(100~200ms 추가)도 고려하여 보조 모듈로의 추가 여부를 판단한다. 이 연구는 메인 시스템 개발과 병행하여 4주 정도 실시하며, 추후 결과에 따라 Phase 7로 모듈 통합을 결정한다.

기타 AI 기술 검토: 더 장기적으로는 **딥러닝 기반 세분화(segmentation)**나 Diffusion 모델을 활용한 결함 검출 가능성도 검토한다. 다만 이러한 기법들은 데이터 요구량과 실시간 처리 측면에서 현재로서는 적합하지 않으므로 연구용으로만 다룬다.

확장 기능 계획: 향후 릴리즈에서 GUI 개선(원격 웹 대시보드 추가, 알람 기능 등), 데이터베이스 이관(대용량 검사 이력 관리를 위해 PostgreSQL 도입) 등의 과제를 계획한다. 또한 다국어 UI 지원, 검사 리포트 자동 이메일 발송 등 운영 편의성을 높이는 기능들도 백로그에 포함시킨다. 이처럼 지속적인 개선 로드맵을 수립하여, 초기 시스템을 시작으로 기능을 점차 발전시켜 나갈 예정이다.

6. 품질 검증 지표 및 테스트 계획

시스템의 성능과 신뢰성을 확보하기 위해 체계적인 테스트 계획을 수립한다. 테스트는 단위 테스트, 통합 테스트, 성능 테스트, 현장 검증의 계층으로 진행된다.

단위 테스트 (Unit Test): 각 모듈별로 예상 입력에 대한 출력이 정확한지 확인하는 자동화된 테스트를 작성한다. 예를 들어 radial_profiler.py의 입력 이미지에 대한 출력 프로파일 길이, color_evaluator.py의 ΔE 계산 정확도 등을 pytest 기반으로 검증한다. 경계 조건(렌즈 검출 안 되는 이미지, 매우 작은 색상 차이 등)에 대한 예외 처리도 테스트한다. 목표는 중요 함수들의 커버리지 80% 이상을 달성하여, 코드 레벨에서 신뢰성을 높이는 것이다.

통합 테스트 (Integration Test): 시스템 파이프라인의 모듈들이 함께 동작하여 올바른 결과를 내는지 검증한다. 여러 장의 테스트 이미지를 순차 처리하는 스크립트를 통해, 전체 흐름의 안정성을 확인한다. 이 과정에서 메모리 누수나 처리 속도 저하가 없는지 모니터링한다. 또한 GUI 통합 후에는 QA 엔지니어가 시나리오 테스트를 수행한다 (예: 설정 변경 -> 검사 실행 -> 로그 생성 -> 리포트 출력까지 일련의 과정 수행).

성능 테스트: 요구된 처리 성능(예: 200ms/장)이 충족되는지 측정한다. 다양한 이미지 해상도와 조명 조건에서 처리 시간을 재고, 95퍼센타일 지연 시간을 산출한다. 만약 특정 단계(예: 렌즈 검출)의 시간이 과도하면 최적화 전후를 비교하여 튜닝 효과를 검증한다. 또한 멀티스레드 동작 시 CPU 사용률, 메모리 사용량을 점검하여 임베디드 환경에서도 안정적으로 동작할 수 있음을 확인한다.

정확도 평가: 검출 정확도를 정량화하기 위해 검증용 데이터셋을 활용한다. 우선 양품(정상) 이미지 30장을 반복 측정하여, 시스템이 전부 OK로 판정하며 ΔE 측정의 **분산이 매우 작음(편차 0.5 이내)**을 확인한다. 이는 시스템의 측정 재현성을 입증한다. 다음으로 다양한 의도적 불량 샘플 (예: 인쇄 잉크 농도를 10% 줄인 렌즈, 패턴 일부러 누락시킨 렌즈 등) 20장 이상을 테스트하여 95% 이상 NG를 정확히 검출하는지를 확인한다. 이때 놓친 결함은 어떤 유형인지 분석하여 알고리즘 보완에 활용한다.

현장 파일럿 테스트: 앞서 5단계 PoC에 기술된 현장 테스트를 통해 실제 생산 환경에서의 성능을 측정한다. 수집된 PoC 기간 데이터를 분석하여, 실가동시 시스템의 평균 검출률, 오탐지율(불량 아님을 NG로 한 비율), **미검지율(불량을 놓친 비율)**을 계산한다. 또한 라인 정지 등의 오작동이 없었는지, UI 조작 시 사용자 실수에 대한 예방 조치가 충분했는지 등의 운용 측면 평가도 실시한다. 이러한 현장 검증 결과를 최종 품질 지표와 비교하여 목표 달성 여부를 판단한다. 예를 들면, "Edge 영역 색상 불량 검출 민감도 98%, 전체 false alarm 2% 이하, 처리 시간 평균 150ms" 등의 기준을 만족하는지 확인한다.

테스트 환경 관리: 테스트용으로 확보한 이미지 세트는 data/raw_images/에 버전관리하며, 각 이미지의 실제 라벨(OK/NG 및 결함 유형)을 메타데이터로 기록해 둔다. 추후 알고리즘 개선 시 회귀 테스트를 수행하여, 같은 데이터셋에 대해 성능이 향상되었는지 또는 오류가 없었는지 지속적으로 검증한다. 또한 운영 중 발견된 특이 사례를 테스트셋에 추가하여 테스트 케이스를 지속 업데이트한다.

7. 리스크 관리 방안

프로젝트 및 시스템 운영상의 잠재 리스크를 식별하고 사전 대응책을 마련한다:

조명 드리프트 및 색상 편차: 시간이 지남에 따라 조명 밝기나 색온도가 변하거나, 카메라 감도가 달라질 위험이 있다. 이를 완화하기 위해 주기적 캘리브레이션 일정을 수립한다 (예: 주 1회 컬러차트로 화이트밸런스 및 광량 보정 실행). 또한 시스템에 조명 모니터링 기능을 넣어, 매 이미지의 평균 밝기나 색상값 로그를 남기고 기준과 벗어날 경우 운영자에게 경고를 준다. 예기치 않은 조명 실패 시에는 즉각 생산라인에 알려 조치를 취하도록 한다.

렌즈 미검출 및 오인식: 렌즈 위치 검출이 실패하거나 엉뚱한 객체를 잡을 리스크가 있다. 대비책으로는 다중 검출 알고리즘 병용 (허프 변환 실패 시 이진화+컨투어 방식 대체 시도) 및 ROI 자동 확장/재시도를 구현한다. 그래도 검출 못 하면 해당 제품은 검사에서 제외하고 라인에서 제거하도록 설계한다. 또한 렌즈가 아닌 이물 등이 검출되는 것을 막기 위해 입력 트레이 설계를 개선하고 배경을 균일하게 유지한다.

다품종 혼류 및 설정 오류: 운영 중 잘못된 SKU 설정이 적용되거나, 작업자가 제품 종류를 혼동해 발생하는 위험이 있다. 이를 방지하기 위해 바코드/QR 코드 스캔으로 SKU를 자동인식하고, 시스템이 잘못된 SKU 설정으로 검사하지 않도록 차단한다. 만약 SKU 선택이 안 된 상태에서는 촬영 트리거 자체를 무시하거나 경고를 낸다. 또한 SKU 설정 변경은 관리자만 할 수 있도록 권한 체계를 두고, 변경 시 로그를 남겨 추적 가능하게 한다.

데이터 부족 및 편향: 새로운 결함 유형이 나타나거나 초기 수집 데이터가 불충분할 위험이 있다. 이 경우 데이터 보강 전략을 마련한다. 예를 들어, 불량 샘플을 합성(이미지 처리 기법으로 색 연하게 만들기 등)하거나, 시험적으로 불량품을 의도적으로 만들어서 데이터를 확보한다. 또 시스템 가동 후에 축적된 NG 사례를 지속적으로 분석하여, 데이터셋을 업데이트하고 알고리즘에 반영한다. 필요하면 어려운 케이스는 rule-based 한계를 인정하고 향후 ML기법을 추가 적용한다.

성능 병목 및 확장 한계: 실제 운영 시 처리 시간이 예상보다 길어지거나, 해상도 상승/다기능 추가로 성능 이슈가 생길 가능성이 있다. 이를 위해 사전 프로파일링으로 병목을 찾아내고, 선택적 최적화(연산 해상도 Δr 조정, ROI 축소 등)를 적용한다. 또한 시스템 구조를 모듈화/스케일아웃 가능하게 설계하여, 필요시 프로세스를 분리하거나 GPU 가속을 옵션으로 추가할 수 있게 해둔다. 예를 들어 PatchCore 같은 무거운 연산은 별도 스레드나 장비에서 돌리고 결과만 통합하는 식으로 탄력적 확장을 고려한다.

알고리즘 한계로 인한 검출 누락: 본 시스템은 색상 기반이므로, 색상이 거의 동일하지만 패턴 배열이 어긋난 결함(예: 프린트 위치 오류)은 감지 못할 수 있다. 이러한 한계는 사전에 이해관계자와 공유하여, 해당 케이스는 추가 수동검사나 딥러닝 보조모듈로 커버하는 계획을 수립한다. 프로젝트 범위를 벗어나는 영역은 명확히 하고, 시스템 성능 목표치를 설정할 때 이를 감안하여 현실적인 기대치를 관리한다.

프로젝트 관리 리스크: 개발 일정 지연이나 인력 부족 등이 발생할 수 있다. 주요 모듈 개발에 대해 버퍼 시간을 확보하고, 2인 이상의 코드 리뷰 및 지식 공유로 특정 인력 의존도를 낮춘다. 또 마일스톤 단위로 진행 상황을 점검하여 이슈를 조기에 발견/해결한다. 범위를 엄격히 관리하여 필수 기능 위주로 우선 구현하고, 부가 기능은 여유가 있을 때 확장하도록 우선순위를 정한다.

8. 유지보수 및 향후 확장성 고려

시스템 배포 후 지속적인 운영 관리와 미래 확장에 대한 계획을 수립한다:

설정 관리와 버전이력: SKU별 기준 프로파일과 임계치는 제품 출시 변화나 품질 기준 변경에 따라 조정이 필요하다. 이를 위해 설정 변경 시마다 버전 번호를 부여하고, 이전 설정을 백업하여 언제든 롤백할 수 있게 한다. 운영 중 UI를 통해 설정을 수정할 경우 관리자 승인 절차를 넣어 오남용을 막고, 설정 비교 diff를 시각화하여 변경 내용을 투명하게 관리한다. 모든 변경 이력은 로그에 남겨 누가 언제 어떤 값을 바꾸었는지 추적 가능하게 한다.

정기 점검 및 캘리브레이션: 조명, 카메라 등의 하드웨어는 정기 유지보수가 필요하다. 주기적으로 렌즈 클리닝, 조명 밝기 점검, 카메라 초점 재조정 등을 수행하고 그 내역을 기록한다. 특히 색상 정확도 유지를 위해 캘리브레이션 SOP를 마련하여, 컬러차트로 화이트밸런스와 노출을 보정하는 절차를 문서화한다. 시스템은 캘리브레이션 시기가 되면 알람을 주고, 수행 여부를 로그에 남겨 품질 이력 감사에 대비한다.

로그 모니터링 및 품질 튜닝: 운영 단계에서 축적되는 검사 로그와 이미지 데이터를 주기적으로 분석한다. 예를 들어 월간 품질 리뷰를 열어 지난 달 오탐/미탐 사례를 확인하고, 그 원인을 토의하여 시스템 설정을 조정하거나 운영 개선책을 도출한다. 이때 데이터 시각화 도구를 사용하여 SKU별 ΔE 추세, 조명 변화에 따른 ΔE 영향 등을 파악하고, 필요시 임계치를 조정하거나 추가 알림 조건을 설정한다. 이러한 지속 개선 프로세스를 통해 시스템의 성능을 점진적으로 높이고 최신 상태로 유지한다.

소프트웨어 업데이트 관리: 라이브러리 버전 업데이트나 OS 환경 변화에 대비하여 정기적으로 의존성 패키지를 점검한다. 새로운 OpenCV나 Python 버전에서 성능 향상이 있을 경우 테스트 후 업그레이드를 검토하고, 보안 패치나 버그 수정이 있는 경우 신속히 적용한다. 코드 레벨에서는 충분한 테스트 커버리지를 확보했으므로, 업데이트 시 회귀 테스트를 통해 기능이 안정적으로 유지되는지 확인한다. 또한 **문서화(Sphinx/MkDocs)**를 통해 개발 API나 설정 방법을 최신화하여, 새로운 팀원이 투입되거나 시간이 지나도 쉽게 유지보수가 가능하도록 한다.

확장성 계획: 시스템 구조는 모듈화되어 있으므로, 향후 새로운 검출 알고리즘이나 센서 장비를 플러그인 형태로 추가할 수 있다. 예를 들어, 고도화 연구에서 긍정 결과가 나온 PatchCore 기반 이상탐지 모듈을 추가로 통합할 수 있다. 이를 위해 ColorEvaluator 단계에 옵션 분기를 마련해 두고, 해당 모듈의 결과를 병합하여 최종 판정에 반영하는 구조로 발전시킬 수 있다. 또한 필요시 다중 카메라 지원이나 한 시스템에서 복수 생산 라인을 처리하도록 하는 등 수평 확장도 고려한다. 데이터베이스를 도입하면 빅데이터 분석 및 AI 모델 학습을 위한 데이터 풀을 구축할 수 있으므로, 일정 수준 데이터가 쌓이면 품질 예측 모델 등 부가가치 기능을 개발하는 방향도 열려 있다.

유저 피드백 및 지원: 최종 사용자인 품질 검사원이나 현장 엔지니어로부터 피드백을 받아 UI/UX 개선 및 기능 추가를 진행한다. 사용 설명서와 교육을 통해 사용자들이 시스템을 잘 활용하도록 돕고, 만일의 장애 시 원격 지원 혹은 신속한 복구가 가능하도록 지원 체계를 마련한다. 예를 들어, 중요 오류 발생 시 개발팀에 자동으로 로그를 전송하거나, 원격에서 진단할 수 있는 툴을 삽입하여 다운타임 최소화를 목표로 한다.

요약하면, 본 계획서에서는 세부 모듈 설계부터 일정, 테스트, 유지보수까지 콘택트렌즈 색상 검사 시스템의 구현 청사진을 제시하였다. 이 통합된 전략을 통해 개발팀은 기술적 리스크를 관리하면서 실현 가능한 일정을 준수할 수 있고, 향후 요구 변화나 기술 발전에도 유연하게 대응할 수 있을 것으로 기대한다. 필요한 경우 각 단계 산출물을 근거로 이해관계자와 소통하며 조율해 나가고, 결과 중심으로 프로젝트를 추진하여 최종적으로 신뢰도 높은 자동 검사 시스템을 성공적으로 구축한다.
